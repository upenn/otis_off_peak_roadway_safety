---
title: "OTIS speed-volume data exploratory analysis"
author: "Chi-Hyun Kim"
date: "Last updated `r Sys.Date()`"
output: 
  html_document:
    toc: true
    toc_float: true
    toc_collapsed: true
    theme: sandstone
knit: (
  function(inputFile, encoding) { 
    rmarkdown::render(
      input = inputFile, 
      encoding = encoding, 
      output_file = paste0(substr(inputFile, 1, nchar(inputFile) - 4), "_", Sys.Date(),'.html')
                     ) 
                                }
      )
---

<!-- Setting style parameters for output document -->

<style>
  body {
    font-family: "Avenir", "Helvetica Neue", Helvetica, Arial, sans-serif !important;
    font-size: 16px !important;
    line-height: 1.6 !important;
    color: #3e3f3a;
    background-color: #ffffff
  }
  title,
  .title {
    font-size: 33px !important;
    font-weight: bold
  }
  h1,
  .h1 {
    font-size: 29px !important;
    font-weight: bold
  }
  h2,
  .h2 {
    font-size: 25px !important;
    font-weight: bold
  }
  h3,
  .h3 {
    font-size: 20px !important;
    font-style: italic
  }
  .caption {
  font-style: italic
  }
  .bold {
  font-weight: bold
  }
</style>

```{r Setup, include = FALSE}

knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)

```

```{r Preliminaries}

library(tidyverse)
library(tidylog)
library(janitor)
library(scales)
library(gt)
library(boxr)
library(sf)
library(mapview)

# Set up remote data access via Box API
box_auth()
box_raw_data_folder <- 362958311858
# Contents of raw data folder
box_raw_data_list <- box_ls(362958311858) %>% as_tibble()

box_processed_data_folder <- 362958210990

# ggplot theming
theme_set(theme_light())

```

```{r Function for table display}

gt_print <- function(data) {
  
  data %>% 
    gt() %>% 
    cols_label_with(fn = ~ snakecase::to_sentence_case(.)) %>% 
    tab_style(cell_text(weight = "bold"), 
              locations = list(cells_column_labels(), 
                               cells_row_groups(), 
                               cells_column_spanners())) %>% 
    tab_style(style = cell_text(style = "italic", align = "right"), 
              locations = list(cells_source_notes())) %>% 
    fmt_number(where(is.numeric), decimals = 2) %>% 
    fmt_percent(contains("percent"), decimals = 2)
  
}

```

```{r Read data}

# File names and ids relating to traffic speed and volume data from OTIS
speed_volume_files <- box_ls(359822034820) %>% as_tibble()

speed_files <- speed_volume_files %>% filter(str_detect(name, "Speed"))
volume_files <- speed_volume_files %>% filter(str_detect(name, "Volume"))

# Batch process files to read in
batch_read_files <- function(data_files_info) {
  
  file_ids <- data_files_info$id
  file_names <- data_files_info$name
  
  custom_read_file <- function(file_id, file_name) {
    
    box_read_csv(file_id) %>% 
      mutate(across(where(is.character), ~na_if(., ""))) %>% 
      mutate(source = file_name, .before = everything())
    
  }
  
  map2(file_ids, file_names, custom_read_file, .progress = TRUE) %>% 
    list_rbind()
  
}

# Initial datasets with clean column names and labels for data year
speed_data_initial <- batch_read_files(speed_files) %>% 
  clean_names() %>% 
  mutate(year = as.numeric(str_extract(source, "\\d{4}")), .after = source) %>% 
  mutate(countdate = mdy(countdate))

volume_data_initial <- batch_read_files(volume_files) %>% 
  clean_names() %>% 
  mutate(year = as.numeric(str_extract(source, "\\d{4}")), .after = source) %>% 
  mutate(countdate = mdy(countdate))

```


```{r, include = FALSE}

glimpse(speed_data_initial)

# Presence of variables and variable completeness by data year
speed_data_initial %>% group_by(year) %>% skimr::skim()

# Tables of the 10 most common values for all character variables, across all years
speed_data_initial %>% 
  select(where(is.character)) %>% 
  map(~ (tabyl(.) %>% 
           arrange(desc(n)) %>% 
           head(10)))

# Some fields are entirely missing or only present in one year's file, but 
# they do not impact interpretation of the data.
# The set of road segments sampled each year are not identical.

# Some years have far more data than other years.

 #                                  .     n   percent
 # Philadelphia_County_Speed_2022.csv 25776 0.4645329
 # Philadelphia_County_Speed_2023.csv 14712 0.2651384
 # Philadelphia_County_Speed_2025.csv  8592 0.1548443
 # Philadelphia_County_Speed_2024.csv  6408 0.1154844

```

```{r, include = FALSE}

glimpse(volume_data_initial)

# Presence of variables and variable completeness by data year
volume_data_initial %>% group_by(year) %>% skimr::skim()

# Tables of the 10 most common values for all character variables, across all years
volume_data_initial %>% 
  select(where(is.character)) %>% 
  map(~ (tabyl(.) %>% 
           arrange(desc(n)) %>% 
           head(10)))

# Some fields are entirely missing or only present in one year's file, but 
# they do not impact interpretation of the data.
# The set of road segments sampled each year are not identical.

# Some years have far more data than other years. (Distribution very similar to speed data.)

 #                            .     n   percent
 # Philadelphia_2022_Volume.csv 25248 0.4618086
 # Philadelphia_2023_Volume.csv 14736 0.2695347
 # Philadelphia_2025_Volume.csv  8256 0.1510097
 # Philadelphia_2024_Volume.csv  6432 0.1176471

```

```{r Export data, include=FALSE}

# speed_data_export <- speed_data_initial %>% 
#   remove_empty()
# 
# box_save_rds(speed_data_export, file_name = "speed_data_v1.rds", dir_id = box_processed_data_folder)
# 
# volume_data_export <- volume_data_initial %>% 
#   remove_empty()
# 
# box_save_rds(volume_data_export, file_name = "volume_data_v1.rds", dir_id = box_processed_data_folder)

```

```{r, include=FALSE}

# What are unique identifiers for each measurement point?
speed_ids <- speed_data_initial %>% 
  distinct(year, recordnum, aadv, fromlmt, tolmt, latitude, longitude)

speed_ids_test1 <- speed_ids %>% 
  # distinct: no rows removed
  distinct(recordnum)

speed_ids_test2 <- speed_ids %>% 
  # distinct: removed 24 rows (4%), 553 rows remaining
  distinct(aadv)

speed_ids_test3 <- speed_ids %>% 
  # distinct: removed 93 rows (16%), 484 rows remaining
  distinct(year, fromlmt, tolmt)

speed_ids_test4 <- speed_ids %>% 
  # distinct: removed 47 rows (8%), 530 rows remaining
  distinct(year, latitude, longitude)

speed_ids_test5 <- speed_ids %>% 
  get_dupes(year, latitude, longitude)

# Look at one group where 3 'recordnum's exist for the same year/long/lat triple
# The records under the same 'aadv' value are exact duplicates except for 'recordnum'
speed_ids_test6 <- speed_data_initial %>% 
  filter(recordnum %in% c("162377", "162537", "162538"))

# Look at the data empirically and see what uniquely identifies each data row (at count hour 0)
# 'aadv' seems to be the most specific variable to pick out a pattern of data at a particular
# 'tolmt' 'fromlmt' pair (just one duplicate). All others have more duplicates.
speed_ids_test7 <- speed_data_initial %>% 
  filter(count_hr == 0) %>% 
  group_by(year, fromlmt, tolmt, pick(contains("speed_"))) %>% 
  summarize(recordnum_unique = n_distinct(recordnum),
            aadv_unique = n_distinct(aadv),
            longitude_unique = n_distinct(longitude),
            latitude_unique = n_distinct(latitude)) %>% 
  ungroup() %>% 
  select(-contains("speed_"))

# Is long/lat pair a unique id for measurement location?
# One coordinate where there are two 'fromlmt' values, otherwise good.
speed_ids_test8 <- speed_data_initial %>% 
  filter(count_hr == 0) %>% 
  group_by(year, longitude, latitude) %>% 
  summarize(recordnum_unique = n_distinct(recordnum),
            aadv_unique = n_distinct(aadv),
            fromlmt_unique = n_distinct(fromlmt),
            tolmt_unique = n_distinct(tolmt)) %>% 
  ungroup() %>% 
  select(-contains("speed_"))

# Is from/tolmt a unique id for measurement location?
# Bunch of pairs where there is more than one coordinate associated.
speed_ids_test9 <- speed_data_initial %>% 
  filter(count_hr == 0) %>% 
  group_by(year, fromlmt, tolmt) %>% 
  summarize(recordnum_unique = n_distinct(recordnum),
            aadv_unique = n_distinct(aadv),
            longitude_unique = n_distinct(longitude),
            latitude_unique = n_distinct(latitude)) %>% 
  ungroup() %>% 
  select(-contains("speed_"))

# Summary: 
# 'recordnum' seems to be the most obvious choice; there are some duplicates of same data under
# different 'recordnum' values, but not too many. 'aadv' is more specific but records annual average
# traffic volume and doesn't seem intended to be used as an ID.
# But note that the same coordinates can have different recorded data across the same dates, 
# perhaps because there were two measurement tubes across the same section of the roadway.
# Further, the same fromlmt/tolmt pair can include multiple coordinates, so 'recordnum' should be
# used as the unique identifier for measurement points.

```

```{r}

# Are there join keys between speed/volume in the data?
# 'recordnum' seems to be the cleanest join key

join_test1 <- speed_data_initial %>% 
  distinct(year, recordnum) %>% 
  full_join(volume_data_initial %>% distinct(year, recordnum), by = c("year", "recordnum"))

# full_join: added no columns
#            > rows only in x                           21
#            > rows only in volume_data_initial %>%..    1
#            > matched rows                            556
#            >                                        =====
#            > rows total                              578

# 'recordnum' is unique across years as well, so the year doesn't need to be specified.
join_test2 <- speed_data_initial %>% 
  distinct(recordnum) %>% 
  full_join(volume_data_initial %>% distinct(recordnum), by = "recordnum")

# full_join: added no columns
#            > rows only in x                           21
#            > rows only in volume_data_initial %>%..    1
#            > matched rows                            556
#            >                                        =====
#            > rows total                              578

# 'aadv' doesn't work as a join key.
join_test3 <- speed_data_initial %>% 
  distinct(year, aadv) %>% 
  full_join(volume_data_initial %>% distinct(year, aadv), by = "aadv")

# full_join: added 2 columns (year.x, year.y)
#            > rows only in x                           20
#            > rows only in volume_data_initial %>%..    1
#            > matched rows                            569    (includes duplicates)
#            >                                        =====
#            > rows total                              590

# Comparing the total volume data from both the speed and volume datasets
joined <- speed_data_initial %>% 
  full_join(volume_data_initial %>% 
              select(year, recordnum, countdate, count_hr, fromlmt, tolmt, longitude, latitude, volcount), 
            by = c("year", "recordnum", "countdate", "count_hr", "fromlmt", "tolmt", "longitude", "latitude")) %>% 
  mutate(volume_agreement = volcount == total) %>% 
  mutate(volume_diff = volcount - total) %>% 
  mutate(volume_diff_category = case_when(volume_diff == 0 ~ "No diff",
                                          volume_diff > 0 ~ "Volume larger",
                                          volume_diff < 0 ~ "Speed total larger",
                                          .default = "One source missing"))

# full_join: added one column (volcount)
#            > rows only in x                             936
#            > rows only in volume_data_initial %>%..     120
#            > matched rows                            54,552
#            >                                        ========
#            > rows total                              55,608

# About 15% of rows have disagreements for total volume between volume and speed
joined %>% tabyl(volume_agreement)

 # volume_agreement     n    percent valid_percent
 #            FALSE  8089 0.14546468     0.1482805
 #             TRUE 46463 0.83554525     0.8517195
 #               NA  1056 0.01899007            NA

# Usually when there are differences the value in the speed dataset is larger, which is strange
joined %>% tabyl(volume_diff_category)

 # volume_diff_category     n    percent
 #              No diff 46463 0.83554525
 #   One source missing  1056 0.01899007
 #   Speed total larger  7250 0.13037692
 #        Volume larger   839 0.01508776

# Upshot: We'll use the volume from the volume data directly since that is what that dataset is for, 
# not the total column in the speed data

```

# Spatial coverage

```{r}

speed_data_geospatial <- speed_data_initial %>% 
  st_as_sf(coords = c("longitude", "latitude"), crs = "EPSG:4326")

volume_data_geospatial <- volume_data_initial %>% 
  st_as_sf(coords = c("longitude", "latitude"), crs = "EPSG:4326")

```

Mapping out points where speed (brown points) and volume (green points) were measured year by year, we see that the measurement locations are quite different between years but very similar (though not identical) between speed/volume measurements in a given year.

## Speed

```{r}

mapview(speed_data_geospatial %>% filter(year == 2022), col.regions = "brown")

mapview(speed_data_geospatial %>% filter(year == 2023), col.regions = "brown")

mapview(speed_data_geospatial %>% filter(year == 2024), col.regions = "brown")

mapview(speed_data_geospatial %>% filter(year == 2025), col.regions = "brown")

```

## Volume

```{r}

mapview(volume_data_geospatial %>% filter(year == 2022), col.regions = "darkgreen")

mapview(volume_data_geospatial %>% filter(year == 2023), col.regions = "darkgreen")

mapview(volume_data_geospatial %>% filter(year == 2024), col.regions = "darkgreen")

mapview(volume_data_geospatial %>% filter(year == 2025), col.regions = "darkgreen")

```

# Temporal coverage

Upshot: Measurement dates vary systematically from year to year. This includes the months covered, the share of weekdays/weekends covered, as well as the share of weekends by month.

The temporal distribution of speed data is quite similar to volume data but not exactly the same.

Coverage of data through the hours of the day is even (i.e., for each measurement instance there is one row for each hour).

## Speed

```{r}

# Daily patterns
speed_data_temporal_coverage_daily <- speed_data_initial %>% 
  group_by(year, countdate) %>% 
  summarize(instances = n_distinct(aadv)) %>% 
  ungroup() %>% 
  mutate(weekday = wday(countdate, label = TRUE)) %>% 
  mutate(weekend = if_else(weekday %in% c("Sat", "Sun"), "Weekend", "Weekday")) %>% 
  mutate(month = month(countdate, label = TRUE))

speed_data_temporal_coverage_daily %>% 
  ggplot(aes(x = countdate, y = instances)) +
  geom_col() +
  labs(title = "Measurement instances by date",
       subtitle = "For speed data")

speed_data_temporal_coverage_daily %>% 
  group_by(year, month, weekend) %>% 
  summarize(instances = sum(instances)) %>% 
  ggplot(aes(x = month, y = instances, fill = weekend)) +
  geom_col(position = position_stack()) +
  facet_wrap(~year) +
  labs(title = "Measurement instances by month",
       subtitle = "For speed data")

speed_data_temporal_coverage_daily %>% 
  group_by(year, weekend) %>% 
  summarize(instances = sum(instances)) %>% 
  ggplot(aes(x = year, y = instances, fill = weekend)) +
  geom_col(position = position_stack()) +
  labs(title = "Measurement instances by weekday/weekend status",
       subtitle = "For speed data")

# Hourly patterns
speed_data_initial %>% 
  group_by(year, count_hr) %>% 
  summarize(instances = n_distinct(aadv)) %>% 
  ungroup() %>% 
  ggplot(aes(x = count_hr, y = instances)) +
  geom_col() +
  facet_wrap(~year)

```

## Volume

```{r}

# Daily patterns
volume_data_temporal_coverage_daily <- volume_data_initial %>% 
  group_by(year, countdate) %>% 
  summarize(instances = n_distinct(aadv)) %>% 
  ungroup() %>% 
  mutate(weekday = wday(countdate, label = TRUE)) %>% 
  mutate(weekend = if_else(weekday %in% c("Sat", "Sun"), "Weekend", "Weekday")) %>% 
  mutate(month = month(countdate, label = TRUE))

volume_data_temporal_coverage_daily %>% 
  ggplot(aes(x = countdate, y = instances)) +
  geom_col() +
  labs(title = "Measurement instances by date",
       subtitle = "For volume data")

volume_data_temporal_coverage_daily %>% 
  group_by(year, month, weekend) %>% 
  summarize(instances = sum(instances)) %>% 
  ggplot(aes(x = month, y = instances, fill = weekend)) +
  geom_col(position = position_stack()) +
  facet_wrap(~year) +
  labs(title = "Measurement instances by month",
       subtitle = "For volume data")

volume_data_temporal_coverage_daily %>% 
  group_by(year, weekend) %>% 
  summarize(instances = sum(instances)) %>% 
  ggplot(aes(x = year, y = instances, fill = weekend)) +
  geom_col(position = position_stack()) +
  labs(title = "Measurement instances by weekday/weekend status",
       subtitle = "For volume data")

# Hourly patterns
volume_data_initial %>% 
  group_by(year, count_hr) %>% 
  summarize(instances = n_distinct(aadv)) %>% 
  ungroup() %>% 
  ggplot(aes(x = count_hr, y = instances)) +
  geom_col() +
  facet_wrap(~year)

```

# Speeding descriptives

```{r}

# Speed data in long format to facilitate analyses
speed_data_long <- speed_data_initial %>% 
  # Join volume data
  left_join(volume_data_initial %>% 
              select(recordnum, countdate, count_hr, volcount)) %>% 
  # Use totals from speed data only if there's no corresponding volume data
  mutate(volume_total = coalesce(volcount, total)) %>% 
  select(year, recordnum, speedlimit, road, fromlmt, tolmt, countdate, count_hr, volume_total, contains("speed_")) %>% 
  pivot_longer(contains("speed_"), 
               values_to = "count", 
               names_to = c("range_low", "range_high"), 
               names_pattern = "speed_(\\d+)_(\\d+)") %>% 
  # Reduce speed categories
  mutate(speed_category_binary =
           if_else(range_high > speedlimit, "Speeding", "Not speeding")) %>% 
  mutate(speed_category_detailed =
           case_when(range_high <= speedlimit ~ "Not speeding",
                     range_low > speedlimit + 20 ~ "More than 20mph over speed limit",
                     range_low > speedlimit + 15 ~ "16-20mph over speed limit",
                     range_low > speedlimit + 10 ~ "11-15mph over speed limit",
                     range_low > speedlimit + 0 ~ "1-10mph over speed limit",
                     .default = "CHECK")) %>% 
  mutate(speed_category_detailed =
           fct_relevel(speed_category_detailed,
                      "Not speeding",
                      "1-10mph over speed limit",
                      "11-15mph over speed limit",
                      "16-20mph over speed limit",
                      "More than 20mph over speed limit"))

```

```{r Join to centerlines}

centerlines <- box_read_rds(2139915462983)

centerlines_ready <- centerlines %>% 
  mutate(roadway_type = 
           case_when(class == 0 ~ "Navy Yard",
                     class == 1 ~ "Expressways",
                     class == 2 ~ "Major Arterial",
                     class == 3 ~ "Minor Arterial",
                     class == 4 ~ "Collector",
                     class == 5 ~ "Local",
                     class == 6 ~ "Driveway",
                     class == 9 ~ "Low Speed Ramps",
                     class == 10 ~ "High Speed Ramps",
                     class == 12 ~ "Non Travable",
                     class == 14 ~ "City Boundary",
                     class == 15 ~ "Walking Connector",
                     class == 18 ~ "Traffic Controlled Crosswalks")) %>% 
  # There are a few industrial/parking types of segments under class == 13 
  # which is not labeled in the data dictionary and is excluded here.
  # filter: removed 73 rows (<1%), 41,186 rows remaining
  filter(!is.na(roadway_type)) %>% 
  select(seg_id, roadway_type) %>% 
  # Index column
  mutate(centerlines_index = row_number()) %>% 
  # Projected CRS
  st_transform("EPSG:2272")
  
speed_data_coords <- speed_data_initial %>% 
  distinct(recordnum, longitude, latitude) %>% 
  st_as_sf(coords = c("longitude", "latitude"), crs = "EPSG:4326") %>% 
  # Projected CRS
  st_transform("EPSG:2272")

# Find the index of the nearest line for each point
nearest_line_indices <- st_nearest_feature(speed_data_coords, centerlines_ready)

# Join by index
# Geometry: measurement points
speed_data_centerlines <- speed_data_coords %>% 
  mutate(centerlines_index = centerlines_ready$centerlines_index[nearest_line_indices]) %>% 
  left_join(centerlines_ready %>% st_drop_geometry()) %>% 
  mutate(roadway_type =
           fct_relevel(roadway_type,
                       "Major Arterial",
                       "Minor Arterial",
                       "Collector",
                       "Local",
                       "High Speed Ramps",
                       "Low Speed Ramps",
                       "Expressways"))

# Geometry: segments where measurements were made
speed_data_centerlines_segments <- speed_data_centerlines %>%
  st_drop_geometry() %>%
  left_join(centerlines_ready %>% 
              select(seg_id)) %>%
  st_as_sf(crs = "EPSG:2272")

```

```{r Speed data ready for analysis}

speed_data_analysis <- speed_data_long %>% 
  left_join(speed_data_centerlines %>% 
              st_drop_geometry() %>% 
              select(recordnum, seg_id, roadway_type)) %>% 
  mutate(time_of_day = 
           case_when(count_hr >= 20 ~ "Off-peak",
                     count_hr >= 16 ~ "Peak",
                     count_hr >= 11 ~ "Off-peak",
                     count_hr >= 7 ~ "Peak",
                     count_hr >= 0 ~ "Off-peak"))

```

## Characteristics of measurement locations

Joining the 2022-2025 speed measurement data spatially to Philadelphia street centerlines, we get this coverage:

```{r}

mapview(speed_data_centerlines, cex = 3) +
  mapview(speed_data_centerlines_segments, zcol = "roadway_type")

```

The distribution of speed measurement points by roadway type is thus:

```{r}

speed_data_analysis %>% 
  distinct(recordnum, roadway_type) %>% 
  tabyl(roadway_type) %>% 
  gt_print()

```

## Speeding by time of day

### Overall

#### Binary

```{r}

speed_data_analysis %>% 
  group_by(recordnum, countdate, count_hr, time_of_day, speed_category_binary) %>% 
  summarize(count = sum(count)) %>% 
  group_by(count_hr, time_of_day, speed_category_binary) %>% 
  summarize(count = sum(count)) %>% 
  mutate(percent = count / sum(count)) %>% 
  ungroup() %>% 
  filter(speed_category_binary != "Not speeding") %>%
  ggplot(aes(x = count_hr, y = percent, fill = time_of_day)) +
  geom_col() +
  scale_y_continuous(labels = label_percent()) +
  scale_fill_manual(values = c("darkred", "darkblue")) +
  labs(title = "Speeding traffic by time of day",
       x = "Hour",
       y = "Percent speeding",
       fill = "Time of day",
       caption = "Source: DVRPC speed measurement data") +
  theme(legend.position = "bottom")

```

#### Detailed

```{r}

speed_data_analysis %>% 
  group_by(recordnum, countdate, count_hr, speed_category_detailed) %>% 
  summarize(count = sum(count)) %>% 
  group_by(count_hr, speed_category_detailed) %>% 
  summarize(count = sum(count)) %>% 
  mutate(percent = count / sum(count)) %>% 
  ungroup() %>% 
  filter(speed_category_detailed != "Not speeding") %>%
  ggplot(aes(x = count_hr, y = percent, fill = speed_category_detailed)) +
  geom_col(position = position_stack()) +
  scale_y_continuous(labels = label_percent()) +
  # scale_fill_manual(values = c("darkred", "darkblue")) +
  labs(title = "Speeding traffic by time of day",
       x = "Hour",
       y = "Percent speeding",
       fill = "Speeding category",
       caption = "Source: DVRPC speed measurement data") +
  theme(legend.position = "right")

```

### By roadway type

#### Binary

```{r}

speed_data_analysis %>% 
  group_by(recordnum, countdate, count_hr, time_of_day, roadway_type, speed_category_binary) %>% 
  summarize(count = sum(count)) %>% 
  group_by(roadway_type, count_hr, time_of_day, speed_category_binary) %>% 
  summarize(count = sum(count)) %>% 
  mutate(percent = count / sum(count)) %>% 
  ungroup() %>% 
  filter(speed_category_binary != "Not speeding") %>%
  ggplot(aes(x = count_hr, y = percent, fill = time_of_day)) +
  geom_col() +
  scale_y_continuous(labels = label_percent()) +
  scale_fill_manual(values = c("darkred", "darkblue")) +
  facet_wrap(~roadway_type) +
  labs(title = "Speeding traffic by time of day",
       x = "Hour",
       y = "Percent speeding",
       fill = "Time of day",
       caption = "Source: DVRPC speed measurement data") +
  theme(legend.position = "bottom")

```

#### Detailed

```{r}

speed_data_analysis %>% 
  group_by(recordnum, countdate, count_hr, roadway_type, speed_category_detailed) %>% 
  summarize(count = sum(count)) %>% 
  group_by(roadway_type, count_hr, speed_category_detailed) %>% 
  summarize(count = sum(count)) %>% 
  mutate(percent = count / sum(count)) %>% 
  ungroup() %>% 
  filter(speed_category_detailed != "Not speeding") %>%
  ggplot(aes(x = count_hr, y = percent, fill = speed_category_detailed)) +
  geom_col(position = position_stack()) +
  scale_y_continuous(labels = label_percent()) +
  facet_wrap(~roadway_type) +
  # scale_fill_manual(values = c("darkred", "darkblue")) +
  labs(title = "Speeding traffic by time of day",
       x = "Hour",
       y = "Percent speeding",
       fill = "Speeding category",
       caption = "Source: DVRPC speed measurement data") +
  theme(legend.position = "right")

```

### Off-peak speed corridors

Where are the roadways where the prevalence of speeding at off-peak hours is the highest?

#### Any speeding

The table below shows roadway type distribution for segments where more than half of traffic speeds in off-peak hours.

```{r}

off_peak_any_speeding <- speed_data_analysis %>% 
  filter(time_of_day == "Off-peak") %>% 
  group_by(recordnum, roadway_type, speed_category_binary) %>% 
  summarize(count = sum(count)) %>% 
  mutate(percent = count / sum(count)) %>% 
  ungroup() %>% 
  filter(speed_category_binary != "Not speeding") 

off_peak_any_speeding_top <- off_peak_any_speeding %>% 
  # filter: removed 419 rows (73%), 158 rows remaining
  filter(percent > 0.5)

off_peak_any_speeding_top %>% 
  tabyl(roadway_type) %>% 
  gt_print()

```

Major arterials and high speed ramps are disproportionately prone to speeding drivers in off-peak hours.

The map below shows the location of these majority-speeding roadways; thickness is proportional to % of speeding traffic.

```{r}

off_peak_any_speeding_top_map <- off_peak_any_speeding_top %>% 
  left_join(speed_data_centerlines_segments %>% 
              select(recordnum)) %>%
  st_as_sf(crs = "EPSG:2272")

mapview(off_peak_any_speeding_high_map, zcol = "roadway_type", lwd = "percent")

```

#### High speeding

The table below shows roadway type distribution for segments where more than 10% of traffic speeds 11mph or more over the limit in off-peak hours.

```{r}

off_peak_high_speeding <- speed_data_analysis %>% 
  filter(time_of_day == "Off-peak") %>% 
  group_by(recordnum, roadway_type, speed_category_detailed) %>% 
  summarize(count = sum(count)) %>% 
  mutate(percent = count / sum(count)) %>% 
  ungroup() %>% 
  filter(!speed_category_detailed %in% c("Not speeding", "1-10mph over speed limit")) %>% 
  group_by(recordnum, roadway_type) %>% 
  summarize(count = sum(count), percent = sum(percent)) %>% 
  ungroup()

off_peak_high_speeding_top <- off_peak_high_speeding %>% 
  # filter: removed 482 rows (84%), 95 rows remaining
  filter(percent > 0.1)

off_peak_high_speeding_top %>% 
  tabyl(roadway_type) %>% 
  gt_print()

```

Major arterials and high speed ramps are even more disproportionately prone to high-speeding drivers in off-peak hours.

The map below shows the location of these high-speeding roadways; thickness is proportional to % of speeding traffic.

```{r}

off_peak_high_speeding_top_map <- off_peak_high_speeding_top %>% 
  left_join(speed_data_centerlines_segments %>% 
              select(recordnum)) %>%
  st_as_sf(crs = "EPSG:2272")

mapview(off_peak_high_speeding_top_map, zcol = "roadway_type", lwd = "percent")

```

## Relationship between volume and speeding

Are drivers more likely to speed for a given roadway type if overall volume is lower?

```{r}

off_peak_volume <- speed_data_analysis %>% 
  filter(time_of_day == "Off-peak") %>% 
  group_by(recordnum, roadway_type) %>% 
  summarize(volume_total = sum(volume_total)) %>% 
  ungroup()

```

### Any speeding

There doesn't seem to be any definitive pattern.

```{r}

off_peak_any_speeding_volume <- off_peak_any_speeding %>% 
  left_join(off_peak_volume)

off_peak_any_speeding_volume %>% 
  ggplot(aes(x = volume_total, y = percent)) +
  geom_point() +
  geom_smooth() +
  facet_wrap(~roadway_type) +
  coord_cartesian(ylim = c(0, 1))

```

### High speeding

There doesn't seem to be any definitive pattern.

```{r}

off_peak_high_speeding_volume <- off_peak_high_speeding %>% 
  left_join(off_peak_volume)

off_peak_high_speeding_volume %>% 
  ggplot(aes(x = volume_total, y = percent)) +
  geom_point() +
  geom_smooth() +
  facet_wrap(~roadway_type) +
  coord_cartesian(ylim = c(0, 1))

```


